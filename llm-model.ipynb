{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9eac27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:11.503289Z",
     "iopub.status.busy": "2024-04-22T15:10:11.502980Z",
     "iopub.status.idle": "2024-04-22T15:10:11.507584Z",
     "shell.execute_reply": "2024-04-22T15:10:11.506719Z"
    },
    "papermill": {
     "duration": 0.017694,
     "end_time": "2024-04-22T15:10:11.509650",
     "exception": false,
     "start_time": "2024-04-22T15:10:11.491956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/huggingface/transformers.git\n",
    "#!huggingface-cli download --resume-download state-spaces/mamba-370m-hf --local-dir mamba-370m-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59c1b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:11.529447Z",
     "iopub.status.busy": "2024-04-22T15:10:11.529175Z",
     "iopub.status.idle": "2024-04-22T15:10:16.404989Z",
     "shell.execute_reply": "2024-04-22T15:10:16.403777Z"
    },
    "papermill": {
     "duration": 4.888617,
     "end_time": "2024-04-22T15:10:16.407870",
     "exception": false,
     "start_time": "2024-04-22T15:10:11.519253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.19.1\r\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers==0.19.1)\r\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting packaging>=20.9 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting requests (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1)\r\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\r\n",
      "Downloading filelock-3.13.4-py3-none-any.whl (11 kB)\r\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./huggingface_hub-0.22.2-py3-none-any.whl\r\n",
      "Saved ./fsspec-2024.3.1-py3-none-any.whl\r\n",
      "Saved ./packaging-24.0-py3-none-any.whl\r\n",
      "Saved ./PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./tqdm-4.66.2-py3-none-any.whl\r\n",
      "Saved ./typing_extensions-4.11.0-py3-none-any.whl\r\n",
      "Saved ./filelock-3.13.4-py3-none-any.whl\r\n",
      "Saved ./requests-2.31.0-py3-none-any.whl\r\n",
      "Saved ./certifi-2024.2.2-py3-none-any.whl\r\n",
      "Saved ./charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./idna-3.7-py3-none-any.whl\r\n",
      "Saved ./urllib3-2.2.1-py3-none-any.whl\r\n",
      "Successfully downloaded tokenizers huggingface-hub fsspec packaging pyyaml tqdm typing-extensions filelock requests certifi charset-normalizer idna urllib3\r\n"
     ]
    }
   ],
   "source": [
    "!pip download tokenizers==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51844254",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:16.443713Z",
     "iopub.status.busy": "2024-04-22T15:10:16.442735Z",
     "iopub.status.idle": "2024-04-22T15:10:23.680804Z",
     "shell.execute_reply": "2024-04-22T15:10:23.679844Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.258864,
     "end_time": "2024-04-22T15:10:23.683478",
     "exception": false,
     "start_time": "2024-04-22T15:10:16.424614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.40.0\r\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting filelock (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/filelock-3.13.4-py3-none-any.whl\r\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/huggingface_hub-0.22.2-py3-none-any.whl\r\n",
      "Collecting numpy>=1.17 (from transformers==4.40.0)\r\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting packaging>=20.0 (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/packaging-24.0-py3-none-any.whl\r\n",
      "Collecting pyyaml>=5.1 (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting regex!=2019.12.17 (from transformers==4.40.0)\r\n",
      "  Downloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/requests-2.31.0-py3-none-any.whl\r\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.40.0)\r\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting tqdm>=4.27 (from transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/tqdm-4.66.2-py3-none-any.whl\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/fsspec-2024.3.1-py3-none-any.whl\r\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/typing_extensions-4.11.0-py3-none-any.whl\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/idna-3.7-py3-none-any.whl\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/urllib3-2.2.1-py3-none-any.whl\r\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.40.0)\r\n",
      "  File was already downloaded /kaggle/working/certifi-2024.2.2-py3-none-any.whl\r\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./transformers-4.40.0-py3-none-any.whl\r\n",
      "Saved ./numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Successfully downloaded transformers huggingface-hub numpy packaging pyyaml regex safetensors tokenizers tqdm filelock requests certifi charset-normalizer fsspec idna typing-extensions urllib3\r\n"
     ]
    }
   ],
   "source": [
    "!pip download transformers==4.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab3cfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:23.713077Z",
     "iopub.status.busy": "2024-04-22T15:10:23.712711Z",
     "iopub.status.idle": "2024-04-22T15:10:23.717161Z",
     "shell.execute_reply": "2024-04-22T15:10:23.716308Z"
    },
    "papermill": {
     "duration": 0.021733,
     "end_time": "2024-04-22T15:10:23.719203",
     "exception": false,
     "start_time": "2024-04-22T15:10:23.697470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip download tokenizers==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce48c35",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:23.748604Z",
     "iopub.status.busy": "2024-04-22T15:10:23.748325Z",
     "iopub.status.idle": "2024-04-22T15:10:23.752190Z",
     "shell.execute_reply": "2024-04-22T15:10:23.751309Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.020348,
     "end_time": "2024-04-22T15:10:23.754214",
     "exception": false,
     "start_time": "2024-04-22T15:10:23.733866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install /kaggle/working/transformers-4.40.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f86f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:23.784500Z",
     "iopub.status.busy": "2024-04-22T15:10:23.783813Z",
     "iopub.status.idle": "2024-04-22T15:10:28.605760Z",
     "shell.execute_reply": "2024-04-22T15:10:28.604657Z"
    },
    "papermill": {
     "duration": 4.839814,
     "end_time": "2024-04-22T15:10:28.608209",
     "exception": false,
     "start_time": "2024-04-22T15:10:23.768395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting triton==2.3.0\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting filelock (from triton==2.3.0)\r\n",
      "  File was already downloaded /kaggle/working/filelock-3.13.4-py3-none-any.whl\r\n",
      "Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Successfully downloaded triton filelock\r\n"
     ]
    }
   ],
   "source": [
    "!pip download triton==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ad678b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:28.644804Z",
     "iopub.status.busy": "2024-04-22T15:10:28.644460Z",
     "iopub.status.idle": "2024-04-22T15:10:28.648718Z",
     "shell.execute_reply": "2024-04-22T15:10:28.647892Z"
    },
    "papermill": {
     "duration": 0.024582,
     "end_time": "2024-04-22T15:10:28.650493",
     "exception": false,
     "start_time": "2024-04-22T15:10:28.625911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install /kaggle/working/triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fc3ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:28.686138Z",
     "iopub.status.busy": "2024-04-22T15:10:28.685886Z",
     "iopub.status.idle": "2024-04-22T15:10:28.689711Z",
     "shell.execute_reply": "2024-04-22T15:10:28.688784Z"
    },
    "papermill": {
     "duration": 0.024028,
     "end_time": "2024-04-22T15:10:28.691858",
     "exception": false,
     "start_time": "2024-04-22T15:10:28.667830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd transformers\n",
    "# pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6731d0aa",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:10:28.727939Z",
     "iopub.status.busy": "2024-04-22T15:10:28.727668Z",
     "iopub.status.idle": "2024-04-22T15:12:17.529008Z",
     "shell.execute_reply": "2024-04-22T15:12:17.527905Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 108.822089,
     "end_time": "2024-04-22T15:12:17.531318",
     "exception": false,
     "start_time": "2024-04-22T15:10:28.709229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting causal-conv1d\r\n",
      "  Downloading causal_conv1d-1.2.0.post2.tar.gz (7.1 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting torch (from causal-conv1d)\r\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting packaging (from causal-conv1d)\r\n",
      "  File was already downloaded /kaggle/working/packaging-24.0-py3-none-any.whl\r\n",
      "Collecting ninja (from causal-conv1d)\r\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting filelock (from torch->causal-conv1d)\r\n",
      "  File was already downloaded /kaggle/working/filelock-3.13.4-py3-none-any.whl\r\n",
      "Collecting typing-extensions>=4.8.0 (from torch->causal-conv1d)\r\n",
      "  File was already downloaded /kaggle/working/typing_extensions-4.11.0-py3-none-any.whl\r\n",
      "Collecting sympy (from torch->causal-conv1d)\r\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch->causal-conv1d)\r\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting jinja2 (from torch->causal-conv1d)\r\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting fsspec (from torch->causal-conv1d)\r\n",
      "  File was already downloaded /kaggle/working/fsspec-2024.3.1-py3-none-any.whl\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->causal-conv1d)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.2.0 (from torch->causal-conv1d)\r\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->causal-conv1d)\r\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch->causal-conv1d)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./causal_conv1d-1.2.0.post2.tar.gz\r\n",
      "Saved ./ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl\r\n",
      "Saved ./torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Saved ./triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./Jinja2-3.1.3-py3-none-any.whl\r\n",
      "Saved ./networkx-3.3-py3-none-any.whl\r\n",
      "Saved ./sympy-1.12-py3-none-any.whl\r\n",
      "Saved ./MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./mpmath-1.3.0-py3-none-any.whl\r\n",
      "Saved ./nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "Successfully downloaded causal-conv1d ninja packaging torch nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 triton typing-extensions filelock fsspec jinja2 networkx sympy MarkupSafe mpmath nvidia-nvjitlink-cu12\r\n",
      "Collecting mamba-ssm\r\n",
      "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting torch (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl\r\n",
      "Collecting packaging (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/packaging-24.0-py3-none-any.whl\r\n",
      "Collecting ninja (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl\r\n",
      "Collecting einops (from mamba-ssm)\r\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting triton (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting transformers (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/transformers-4.40.0-py3-none-any.whl\r\n",
      "Collecting filelock (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/filelock-3.13.4-py3-none-any.whl\r\n",
      "Collecting typing-extensions>=4.8.0 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/typing_extensions-4.11.0-py3-none-any.whl\r\n",
      "Collecting sympy (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/sympy-1.12-py3-none-any.whl\r\n",
      "Collecting networkx (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/networkx-3.3-py3-none-any.whl\r\n",
      "Collecting jinja2 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/Jinja2-3.1.3-py3-none-any.whl\r\n",
      "Collecting fsspec (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/fsspec-2024.3.1-py3-none-any.whl\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\r\n",
      "Collecting triton (from mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/huggingface_hub-0.22.2-py3-none-any.whl\r\n",
      "Collecting numpy>=1.17 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting pyyaml>=5.1 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting regex!=2019.12.17 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting requests (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/requests-2.31.0-py3-none-any.whl\r\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting safetensors>=0.4.1 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting tqdm>=4.27 (from transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/tqdm-4.66.2-py3-none-any.whl\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Collecting idna<4,>=2.5 (from requests->transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/idna-3.7-py3-none-any.whl\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/urllib3-2.2.1-py3-none-any.whl\r\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/certifi-2024.2.2-py3-none-any.whl\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch->mamba-ssm)\r\n",
      "  File was already downloaded /kaggle/working/mpmath-1.3.0-py3-none-any.whl\r\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./mamba_ssm-1.2.0.post1.tar.gz\r\n",
      "Saved ./einops-0.7.0-py3-none-any.whl\r\n",
      "Successfully downloaded mamba-ssm einops ninja packaging torch triton nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 transformers huggingface-hub fsspec numpy pyyaml regex safetensors tokenizers tqdm typing-extensions filelock jinja2 networkx requests sympy certifi charset-normalizer idna MarkupSafe mpmath urllib3 nvidia-nvjitlink-cu12\r\n"
     ]
    }
   ],
   "source": [
    "!pip download causal-conv1d\n",
    "!pip download mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280c1cec",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:17.757708Z",
     "iopub.status.busy": "2024-04-22T15:12:17.756845Z",
     "iopub.status.idle": "2024-04-22T15:12:17.761386Z",
     "shell.execute_reply": "2024-04-22T15:12:17.760553Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.142417,
     "end_time": "2024-04-22T15:12:17.763307",
     "exception": false,
     "start_time": "2024-04-22T15:12:17.620890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install /kaggle/working/causal_conv1d-1.2.0.post2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f28f62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:17.944085Z",
     "iopub.status.busy": "2024-04-22T15:12:17.943348Z",
     "iopub.status.idle": "2024-04-22T15:12:19.786699Z",
     "shell.execute_reply": "2024-04-22T15:12:19.785740Z"
    },
    "papermill": {
     "duration": 1.936316,
     "end_time": "2024-04-22T15:12:19.789138",
     "exception": false,
     "start_time": "2024-04-22T15:12:17.852822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops==0.7.0\r\n",
      "  File was already downloaded /kaggle/working/einops-0.7.0-py3-none-any.whl\r\n",
      "Successfully downloaded einops\r\n"
     ]
    }
   ],
   "source": [
    "!pip download einops==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796a6140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:19.969724Z",
     "iopub.status.busy": "2024-04-22T15:12:19.969145Z",
     "iopub.status.idle": "2024-04-22T15:12:19.973392Z",
     "shell.execute_reply": "2024-04-22T15:12:19.972569Z"
    },
    "papermill": {
     "duration": 0.096355,
     "end_time": "2024-04-22T15:12:19.975269",
     "exception": false,
     "start_time": "2024-04-22T15:12:19.878914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install /kaggle/working/einops-0.7.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b57c0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:20.153720Z",
     "iopub.status.busy": "2024-04-22T15:12:20.152975Z",
     "iopub.status.idle": "2024-04-22T15:12:20.156968Z",
     "shell.execute_reply": "2024-04-22T15:12:20.155998Z"
    },
    "papermill": {
     "duration": 0.095222,
     "end_time": "2024-04-22T15:12:20.158785",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.063563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install /kaggle/working/mamba_ssm-1.2.0.post1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b573fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:20.337183Z",
     "iopub.status.busy": "2024-04-22T15:12:20.336909Z",
     "iopub.status.idle": "2024-04-22T15:12:20.341565Z",
     "shell.execute_reply": "2024-04-22T15:12:20.340661Z"
    },
    "papermill": {
     "duration": 0.096801,
     "end_time": "2024-04-22T15:12:20.343464",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.246663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import re\n",
    "# import bisect\n",
    "# from pathlib import Path\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from datasets import Dataset\n",
    "# from spacy.lang.en import English\n",
    "# from transformers.models.deberta_v2 import DebertaV2ForTokenClassification, DebertaV2TokenizerFast\n",
    "# from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "# from transformers.trainer import Trainer\n",
    "# from transformers.training_args import TrainingArguments\n",
    "# from transformers.data.data_collator import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a81033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:20.524717Z",
     "iopub.status.busy": "2024-04-22T15:12:20.524079Z",
     "iopub.status.idle": "2024-04-22T15:12:20.527989Z",
     "shell.execute_reply": "2024-04-22T15:12:20.527177Z"
    },
    "papermill": {
     "duration": 0.096616,
     "end_time": "2024-04-22T15:12:20.529982",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.433366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModel, AutoTokenizer, AdamW, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea491c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:20.710965Z",
     "iopub.status.busy": "2024-04-22T15:12:20.710328Z",
     "iopub.status.idle": "2024-04-22T15:12:20.714238Z",
     "shell.execute_reply": "2024-04-22T15:12:20.713401Z"
    },
    "papermill": {
     "duration": 0.097429,
     "end_time": "2024-04-22T15:12:20.716233",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.618804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gemma = AutoModel.from_pretrained(\"/kaggle/input/gemma/transformers/2b/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2857512d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:20.894795Z",
     "iopub.status.busy": "2024-04-22T15:12:20.894074Z",
     "iopub.status.idle": "2024-04-22T15:12:20.897908Z",
     "shell.execute_reply": "2024-04-22T15:12:20.897055Z"
    },
    "papermill": {
     "duration": 0.0949,
     "end_time": "2024-04-22T15:12:20.899661",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.804761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# danube = AutoModel.from_pretrained(\"/kaggle/input/h2o-danube-1-8b-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eaf689c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:21.079609Z",
     "iopub.status.busy": "2024-04-22T15:12:21.078877Z",
     "iopub.status.idle": "2024-04-22T15:12:21.082719Z",
     "shell.execute_reply": "2024-04-22T15:12:21.081905Z"
    },
    "papermill": {
     "duration": 0.096556,
     "end_time": "2024-04-22T15:12:21.084640",
     "exception": false,
     "start_time": "2024-04-22T15:12:20.988084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     total_params = sum(p.numel() for p in model.parameters())\n",
    "#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#     return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21d7254f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:21.264422Z",
     "iopub.status.busy": "2024-04-22T15:12:21.264080Z",
     "iopub.status.idle": "2024-04-22T15:12:21.268012Z",
     "shell.execute_reply": "2024-04-22T15:12:21.267142Z"
    },
    "papermill": {
     "duration": 0.096412,
     "end_time": "2024-04-22T15:12:21.269898",
     "exception": false,
     "start_time": "2024-04-22T15:12:21.173486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_total_params, bert_trainable_params = count_parameters(gemma)\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5dfc840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:21.450774Z",
     "iopub.status.busy": "2024-04-22T15:12:21.450012Z",
     "iopub.status.idle": "2024-04-22T15:12:21.453923Z",
     "shell.execute_reply": "2024-04-22T15:12:21.453088Z"
    },
    "papermill": {
     "duration": 0.097236,
     "end_time": "2024-04-22T15:12:21.455999",
     "exception": false,
     "start_time": "2024-04-22T15:12:21.358763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_total_params, bert_trainable_params = count_parameters(danube)\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0214695c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:21.638646Z",
     "iopub.status.busy": "2024-04-22T15:12:21.638034Z",
     "iopub.status.idle": "2024-04-22T15:12:21.641959Z",
     "shell.execute_reply": "2024-04-22T15:12:21.641076Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.096893,
     "end_time": "2024-04-22T15:12:21.643842",
     "exception": false,
     "start_time": "2024-04-22T15:12:21.546949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# longformer = AutoModel.from_pretrained(\"allenai/longformer-large-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d4c61e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:21.825324Z",
     "iopub.status.busy": "2024-04-22T15:12:21.824716Z",
     "iopub.status.idle": "2024-04-22T15:12:21.828493Z",
     "shell.execute_reply": "2024-04-22T15:12:21.827714Z"
    },
    "papermill": {
     "duration": 0.096377,
     "end_time": "2024-04-22T15:12:21.830393",
     "exception": false,
     "start_time": "2024-04-22T15:12:21.734016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_total_params, bert_trainable_params = count_parameters(longformer)\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc6cfdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.009033Z",
     "iopub.status.busy": "2024-04-22T15:12:22.008405Z",
     "iopub.status.idle": "2024-04-22T15:12:22.012108Z",
     "shell.execute_reply": "2024-04-22T15:12:22.011283Z"
    },
    "papermill": {
     "duration": 0.095544,
     "end_time": "2024-04-22T15:12:22.013939",
     "exception": false,
     "start_time": "2024-04-22T15:12:21.918395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd0c640f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.192520Z",
     "iopub.status.busy": "2024-04-22T15:12:22.191972Z",
     "iopub.status.idle": "2024-04-22T15:12:22.195848Z",
     "shell.execute_reply": "2024-04-22T15:12:22.195031Z"
    },
    "papermill": {
     "duration": 0.095555,
     "end_time": "2024-04-22T15:12:22.197739",
     "exception": false,
     "start_time": "2024-04-22T15:12:22.102184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_total_params, bert_trainable_params = count_parameters(deberta)\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "852e256d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.383363Z",
     "iopub.status.busy": "2024-04-22T15:12:22.383029Z",
     "iopub.status.idle": "2024-04-22T15:12:22.387000Z",
     "shell.execute_reply": "2024-04-22T15:12:22.386160Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.101398,
     "end_time": "2024-04-22T15:12:22.388803",
     "exception": false,
     "start_time": "2024-04-22T15:12:22.287405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.nn.ModuleList([layer for i, layer in enumerate(danube.layers) if i < 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6e1953e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.573492Z",
     "iopub.status.busy": "2024-04-22T15:12:22.572641Z",
     "iopub.status.idle": "2024-04-22T15:12:22.576805Z",
     "shell.execute_reply": "2024-04-22T15:12:22.575977Z"
    },
    "papermill": {
     "duration": 0.09861,
     "end_time": "2024-04-22T15:12:22.578614",
     "exception": false,
     "start_time": "2024-04-22T15:12:22.480004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_total_params, bert_trainable_params = count_parameters(torch.nn.ModuleList([layer for i, layer in enumerate(danube.layers) if i < 8]))\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2245b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.759211Z",
     "iopub.status.busy": "2024-04-22T15:12:22.758863Z",
     "iopub.status.idle": "2024-04-22T15:12:22.763193Z",
     "shell.execute_reply": "2024-04-22T15:12:22.762419Z"
    },
    "papermill": {
     "duration": 0.097284,
     "end_time": "2024-04-22T15:12:22.765216",
     "exception": false,
     "start_time": "2024-04-22T15:12:22.667932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig\n",
    "# from transformers.models.llama.modeling_llama import *\n",
    "\n",
    "# # 加载预训练的 BERT 模型配置\n",
    "# config = AutoConfig.from_pretrained('/kaggle/input/gemma/transformers/2b/2/config.json')\n",
    "\n",
    "# # 我们将修改配置以仅使用前三层\n",
    "# #config.num_hidden_layers = 18\n",
    "\n",
    "# # 加载模型，根据修改后的配置\n",
    "# model1 = LlamaModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea77bb17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:22.946242Z",
     "iopub.status.busy": "2024-04-22T15:12:22.945893Z",
     "iopub.status.idle": "2024-04-22T15:12:22.950068Z",
     "shell.execute_reply": "2024-04-22T15:12:22.949128Z"
    },
    "papermill": {
     "duration": 0.09658,
     "end_time": "2024-04-22T15:12:22.952143",
     "exception": false,
     "start_time": "2024-04-22T15:12:22.855563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModel, AutoConfig\n",
    "\n",
    "# # 自动加载配置\n",
    "# config = AutoConfig.from_pretrained('/kaggle/input/gemma/transformers/2b/2/')\n",
    "# config.num_hidden_layers = 5\n",
    "# # 自动加载模型\n",
    "# model = AutoModel.from_pretrained('/kaggle/input/gemma/transformers/2b/2/', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc043d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:23.133025Z",
     "iopub.status.busy": "2024-04-22T15:12:23.132683Z",
     "iopub.status.idle": "2024-04-22T15:12:23.136486Z",
     "shell.execute_reply": "2024-04-22T15:12:23.135708Z"
    },
    "papermill": {
     "duration": 0.095978,
     "end_time": "2024-04-22T15:12:23.138421",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.042443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a929153b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:23.317435Z",
     "iopub.status.busy": "2024-04-22T15:12:23.317118Z",
     "iopub.status.idle": "2024-04-22T15:12:23.320917Z",
     "shell.execute_reply": "2024-04-22T15:12:23.320090Z"
    },
    "papermill": {
     "duration": 0.09559,
     "end_time": "2024-04-22T15:12:23.322780",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.227190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers.models.llama.modeling_llama import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45dec663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:23.501296Z",
     "iopub.status.busy": "2024-04-22T15:12:23.500973Z",
     "iopub.status.idle": "2024-04-22T15:12:23.504735Z",
     "shell.execute_reply": "2024-04-22T15:12:23.503890Z"
    },
    "papermill": {
     "duration": 0.095523,
     "end_time": "2024-04-22T15:12:23.506579",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.411056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.num_hidden_layers = 10\n",
    "\n",
    "# model2 = LlamaModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e3de749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:23.701559Z",
     "iopub.status.busy": "2024-04-22T15:12:23.701229Z",
     "iopub.status.idle": "2024-04-22T15:12:23.705121Z",
     "shell.execute_reply": "2024-04-22T15:12:23.704286Z"
    },
    "papermill": {
     "duration": 0.102025,
     "end_time": "2024-04-22T15:12:23.707122",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.605097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.nn.ModuleList([layer for i, layer in enumerate(model2.layers) if i < 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4c8782f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:23.888323Z",
     "iopub.status.busy": "2024-04-22T15:12:23.888006Z",
     "iopub.status.idle": "2024-04-22T15:12:23.891776Z",
     "shell.execute_reply": "2024-04-22T15:12:23.891008Z"
    },
    "papermill": {
     "duration": 0.0971,
     "end_time": "2024-04-22T15:12:23.893819",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.796719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3eea7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:24.076120Z",
     "iopub.status.busy": "2024-04-22T15:12:24.075307Z",
     "iopub.status.idle": "2024-04-22T15:12:24.079383Z",
     "shell.execute_reply": "2024-04-22T15:12:24.078693Z"
    },
    "papermill": {
     "duration": 0.096926,
     "end_time": "2024-04-22T15:12:24.081272",
     "exception": false,
     "start_time": "2024-04-22T15:12:23.984346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     total_params = sum(p.numel() for p in model.parameters())\n",
    "#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#     return total_params, trainable_params\n",
    "\n",
    "# bert_total_params, bert_trainable_params = count_parameters(model1)\n",
    "# print(f\"BERT Total Parameters: {bert_total_params}\")\n",
    "# print(f\"BERT Trainable Parameters: {bert_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "268b2f3a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-22T15:12:24.261556Z",
     "iopub.status.busy": "2024-04-22T15:12:24.260959Z",
     "iopub.status.idle": "2024-04-22T15:12:24.265025Z",
     "shell.execute_reply": "2024-04-22T15:12:24.264160Z"
    },
    "papermill": {
     "duration": 0.096445,
     "end_time": "2024-04-22T15:12:24.266941",
     "exception": false,
     "start_time": "2024-04-22T15:12:24.170496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base_model = AutoModel.from_pretrained(self.cfg.model_name,config=self.model_config,quantization_config=bnb_config)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4511635,
     "sourceId": 7723136,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 6216,
     "sourceId": 11384,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 135.818179,
   "end_time": "2024-04-22T15:12:24.575907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-22T15:10:08.757728",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
